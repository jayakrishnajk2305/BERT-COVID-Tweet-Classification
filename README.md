# **BERT COVID Tweet Classification**  
ğŸ“¢ **A deep learning project using BERT to classify COVID-19-related tweets with high accuracy.**  

---

## ğŸ“œ **Project Overview**  
This repository contains an **NLP-based classification system** that analyzes **COVID-19-related tweets** to determine whether they contain relevant pandemic-related information.  
We fine-tune **BERT (Bidirectional Encoder Representations from Transformers)** to enhance text classification performance using **TensorFlow and Hugging Face Transformers**.

---

## âœ¨ **Key Features**  
ğŸ”¹ **Fine-tuned BERT Model** â€“ Adapted for classifying COVID-related tweets with high accuracy.  
ğŸ”¹ **Robust Evaluation Metrics** â€“ Accuracy, Precision, Recall, and F1-score used for performance validation.  
ğŸ”¹ **Preprocessing Pipeline** â€“ Includes text cleaning, tokenization, and handling imbalanced data.  
ğŸ”¹ **Visualization** â€“ Confusion matrices and performance graphs for insight into model effectiveness.  
ğŸ”¹ **Automated Training & Prediction Pipeline** â€“ Supports real-time tweet classification.  

---

## ğŸ“Š **Results & Performance**  
The fine-tuned **BERT model** delivered the following performance:  

- **Accuracy:** **94.18%**  
- **F1-Score:** **85.73**  
- **Precision:** **98.1%**  
- **Recall:** **99.0%**  

ğŸ“ˆ **Performance Metrics Visualizations**:  
- Confusion Matrix for Model Evaluation  
- Test Accuracy over Training Epochs  

---

## ğŸ› ï¸ **Methodology**  

### **1ï¸âƒ£ Data Collection & Preprocessing**  
âœ… Collected **COVID-19-related tweets** from the CDC, CNN, and other verified sources.  
âœ… Applied **text cleaning techniques**:  
   - Removed **retweets (RT)**, URLs, HTML entities, numbers, and special characters.  
   - Converted all text to **lowercase** for uniformity.  
âœ… Tokenized text using **BERT Tokenizer** for efficient model training.  

### **2ï¸âƒ£ Model Training**  
âœ… Fine-tuned **BERT (bert-base-uncased)** on **cleaned and labeled tweet data**.  
âœ… Splitted dataset into **70% training and 30% validation** for better generalization.  
âœ… Optimized the model using:  
   - **AdamW Optimizer**  
   - **Learning rate scheduling**  

### **3ï¸âƒ£ Model Evaluation & Testing**  
âœ… Evaluated performance using **accuracy, precision, recall, and F1-score**.  
âœ… Visualized **Confusion Matrix** to analyze classification errors.  

### **4ï¸âƒ£ Prediction on New Data**  
âœ… Classified **unlabeled tweets** from various sources using the trained model.  
âœ… Generated **automated reports** based on predictions.  

---

## ğŸ“‚ **Repository Structure**  

ğŸ“ `data/` â€“ Contains labeled and unlabeled tweet datasets.  
ğŸ“ `notebooks/` â€“ Jupyter Notebooks for training and evaluation.  
ğŸ“ `scripts/` â€“ Python scripts for preprocessing, training, and prediction.  
ğŸ“ `results/` â€“ Performance metrics, confusion matrix, and accuracy graphs.  

---

## ğŸ”§ **Installation & Setup**  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/yourusername/BERT-COVID-Tweet-Classification.git
cd BERT-COVID-Tweet-Classification
```

### **2ï¸âƒ£ Install Required Libraries**  
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Run Training Script**  
```bash
python scripts/train_model.py
```

### **4ï¸âƒ£ Run Prediction on New Data**  
```bash
python scripts/predict.py --input data/new_tweets.csv
```

---

## ğŸ“Œ **Example Usage**  

### **Training the Model**
```python
from transformers import BertTokenizer, TFBertForSequenceClassification
import tensorflow as tf

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = TFBertForSequenceClassification.from_pretrained("bert-base-uncased")

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Train model on dataset
model.fit(train_dataset, epochs=5, validation_data=validation_dataset)
```

### **Predicting New Tweets**
```python
input_text = "COVID-19 cases are rising again. Stay safe!"
tokens = tokenizer(input_text, return_tensors="tf", truncation=True, padding=True)
output = model.predict(tokens)
predicted_class = tf.argmax(output.logits, axis=1).numpy()[0]
print(f"Predicted Label: {predicted_class}")
```

---

## ğŸš€ **Future Improvements**  
âœ… Expand dataset with **real-time Twitter API data** for continuous learning.  
âœ… Integrate **RoBERTa & DistilBERT** for comparative analysis.  
âœ… Deploy as an **API using Flask or FastAPI** for real-time tweet classification.  
âœ… Extend classification to **multi-label prediction** (e.g., news, misinformation, vaccine updates).  

---

## ğŸ“– **About Me**  
ğŸ‘‹ Hi! Iâ€™m **Jaya Krishna**, a passionate **Data Scientist & NLP Engineer** specializing in **BERT-based text classification and Deep Learning models**.  

ğŸ“Œ **Let's Connect!**  
ğŸ“© **Email**: jaya2305krishna@gmail.com  
ğŸ”— **LinkedIn**: [linkedin.com/in/jaya23krishna](https://linkedin.com/in/jaya23krishna)  
ğŸŒŸ **GitHub**: [github.com/jaya23krishna](https://github.com/jaya23krishna)  

ğŸš€ Feel free to fork, contribute, or star â­ this project!  

---

